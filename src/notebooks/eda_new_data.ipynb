{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import wandb\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 109)\n",
      "           eps1   eps2   eps3   eps4   t1 [mm]  t2 [mm]  t3 [mm]  t4 [mm]  \\\n",
      "sample n.                                                                   \n",
      "1             17     19      3      7      120      120       84       36   \n",
      "2             14     18     11      4       36       24      108       24   \n",
      "3             12     17     12      5       48       12       96       96   \n",
      "4             20      3     18     18      108       72       12       36   \n",
      "5              6      1      1      9       60       36       24       96   \n",
      "\n",
      "                  2      2.02  ...      3.82      3.84      3.86      3.88  \\\n",
      "sample n.                      ...                                           \n",
      "1          0.830886  0.590904  ...  0.348554  0.763909  0.898857  0.924594   \n",
      "2          0.594543  0.506873  ...  0.624806  0.703088  0.738096  0.743039   \n",
      "3          0.602679  0.732174  ...  0.700986  0.714886  0.690121  0.619208   \n",
      "4          0.956440  0.933687  ...  0.567249  0.306811  0.640547  0.849548   \n",
      "5          0.497800  0.432769  ...  0.928810  0.926873  0.921459  0.911978   \n",
      "\n",
      "                3.9      3.92      3.94      3.96      3.98         4  \n",
      "sample n.                                                              \n",
      "1          0.913307  0.845180  0.541802  0.307068  0.723563  0.810385  \n",
      "2          0.720383  0.663658  0.557745  0.390332  0.241558  0.356251  \n",
      "3          0.491060  0.354832  0.403744  0.564909  0.681411  0.742819  \n",
      "4          0.920894  0.947998  0.958739  0.961157  0.956499  0.940564  \n",
      "5          0.897336  0.875916  0.845762  0.805352  0.755381  0.700955  \n",
      "\n",
      "[5 rows x 109 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = r\"C:\\Users\\mktha\\Documents\\projects\\felix\\data\\RawDataMagExtended(newdataset).csv\"\n",
    "\n",
    "df_mag = pd.read_csv(csv_path, header=0, index_col=0)\n",
    "\n",
    "csv_path = r\"C:\\Users\\mktha\\Documents\\projects\\felix\\data\\mag30000.csv\"\n",
    "\n",
    "df_mag_2 = pd.read_csv(csv_path, header=0, index_col=0)\n",
    "\n",
    "csv_path = r\"C:\\Users\\mktha\\Documents\\projects\\felix\\data\\mag100000.csv\"\n",
    "\n",
    "df_mag_3 = pd.read_csv(csv_path, header=0, index_col=0)\n",
    "\n",
    "# concat the two dataframes\n",
    "df_mag = pd.concat([df_mag, df_mag_2, df_mag_3], axis=0)\n",
    "\n",
    "# print the shape\n",
    "print(df_mag.shape)\n",
    "\n",
    "# get the headers\n",
    "headers = df_mag.columns.values.tolist()\n",
    "print(df_mag.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640000, 109)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps1</th>\n",
       "      <th>eps2</th>\n",
       "      <th>eps3</th>\n",
       "      <th>eps4</th>\n",
       "      <th>t1 [mm]</th>\n",
       "      <th>t2 [mm]</th>\n",
       "      <th>t3 [mm]</th>\n",
       "      <th>t4 [mm]</th>\n",
       "      <th>2</th>\n",
       "      <th>2.02</th>\n",
       "      <th>...</th>\n",
       "      <th>3.82</th>\n",
       "      <th>3.84</th>\n",
       "      <th>3.86</th>\n",
       "      <th>3.88</th>\n",
       "      <th>3.9</th>\n",
       "      <th>3.92</th>\n",
       "      <th>3.94</th>\n",
       "      <th>3.96</th>\n",
       "      <th>3.98</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.504931</td>\n",
       "      <td>10.509688</td>\n",
       "      <td>10.504641</td>\n",
       "      <td>10.498042</td>\n",
       "      <td>66.027075</td>\n",
       "      <td>66.020588</td>\n",
       "      <td>66.042844</td>\n",
       "      <td>65.928844</td>\n",
       "      <td>6.673346e-01</td>\n",
       "      <td>0.667541</td>\n",
       "      <td>...</td>\n",
       "      <td>6.653535e-01</td>\n",
       "      <td>6.656284e-01</td>\n",
       "      <td>6.656958e-01</td>\n",
       "      <td>6.655348e-01</td>\n",
       "      <td>0.665172</td>\n",
       "      <td>6.649860e-01</td>\n",
       "      <td>6.649359e-01</td>\n",
       "      <td>0.665539</td>\n",
       "      <td>6.655460e-01</td>\n",
       "      <td>6.656456e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.764077</td>\n",
       "      <td>5.762281</td>\n",
       "      <td>5.767256</td>\n",
       "      <td>5.767020</td>\n",
       "      <td>34.456469</td>\n",
       "      <td>34.455533</td>\n",
       "      <td>34.504578</td>\n",
       "      <td>34.474124</td>\n",
       "      <td>2.159923e-01</td>\n",
       "      <td>0.216059</td>\n",
       "      <td>...</td>\n",
       "      <td>2.157661e-01</td>\n",
       "      <td>2.157362e-01</td>\n",
       "      <td>2.157286e-01</td>\n",
       "      <td>2.158523e-01</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>2.159365e-01</td>\n",
       "      <td>2.163339e-01</td>\n",
       "      <td>0.215825</td>\n",
       "      <td>2.160998e-01</td>\n",
       "      <td>2.158734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.850462e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.928594e-17</td>\n",
       "      <td>4.163336e-17</td>\n",
       "      <td>6.206335e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>5.337120e-01</td>\n",
       "      <td>0.534212</td>\n",
       "      <td>...</td>\n",
       "      <td>5.322081e-01</td>\n",
       "      <td>5.324213e-01</td>\n",
       "      <td>5.320344e-01</td>\n",
       "      <td>5.318954e-01</td>\n",
       "      <td>0.531747</td>\n",
       "      <td>5.305231e-01</td>\n",
       "      <td>5.308626e-01</td>\n",
       "      <td>0.531658</td>\n",
       "      <td>5.316424e-01</td>\n",
       "      <td>5.315743e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.236799e-01</td>\n",
       "      <td>0.723734</td>\n",
       "      <td>...</td>\n",
       "      <td>7.213209e-01</td>\n",
       "      <td>7.217035e-01</td>\n",
       "      <td>7.217745e-01</td>\n",
       "      <td>7.216917e-01</td>\n",
       "      <td>0.721434</td>\n",
       "      <td>7.207618e-01</td>\n",
       "      <td>7.209027e-01</td>\n",
       "      <td>0.721286</td>\n",
       "      <td>7.217253e-01</td>\n",
       "      <td>7.214615e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>8.369641e-01</td>\n",
       "      <td>0.837273</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360165e-01</td>\n",
       "      <td>8.363003e-01</td>\n",
       "      <td>8.363553e-01</td>\n",
       "      <td>8.363261e-01</td>\n",
       "      <td>0.835910</td>\n",
       "      <td>8.359788e-01</td>\n",
       "      <td>8.358903e-01</td>\n",
       "      <td>0.836058</td>\n",
       "      <td>8.364130e-01</td>\n",
       "      <td>8.364736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>9.946186e-01</td>\n",
       "      <td>0.994560</td>\n",
       "      <td>...</td>\n",
       "      <td>9.943800e-01</td>\n",
       "      <td>9.944133e-01</td>\n",
       "      <td>9.946468e-01</td>\n",
       "      <td>9.943963e-01</td>\n",
       "      <td>0.994473</td>\n",
       "      <td>9.942726e-01</td>\n",
       "      <td>9.948500e-01</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>9.947453e-01</td>\n",
       "      <td>9.940722e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               eps1           eps2           eps3           eps4   \\\n",
       "count  640000.000000  640000.000000  640000.000000  640000.000000   \n",
       "mean       10.504931      10.509688      10.504641      10.498042   \n",
       "std         5.764077       5.762281       5.767256       5.767020   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         6.000000       6.000000       6.000000       5.000000   \n",
       "50%        11.000000      11.000000      11.000000      10.000000   \n",
       "75%        15.000000      16.000000      16.000000      15.000000   \n",
       "max        20.000000      20.000000      20.000000      20.000000   \n",
       "\n",
       "             t1 [mm]        t2 [mm]        t3 [mm]        t4 [mm]  \\\n",
       "count  640000.000000  640000.000000  640000.000000  640000.000000   \n",
       "mean       66.027075      66.020588      66.042844      65.928844   \n",
       "std        34.456469      34.455533      34.504578      34.474124   \n",
       "min        12.000000      12.000000      12.000000      12.000000   \n",
       "25%        36.000000      36.000000      36.000000      36.000000   \n",
       "50%        72.000000      60.000000      72.000000      60.000000   \n",
       "75%        96.000000      96.000000      96.000000      96.000000   \n",
       "max       120.000000     120.000000     120.000000     120.000000   \n",
       "\n",
       "                  2           2.02  ...          3.82          3.84  \\\n",
       "count  6.400000e+05  640000.000000  ...  6.400000e+05  6.400000e+05   \n",
       "mean   6.673346e-01       0.667541  ...  6.653535e-01  6.656284e-01   \n",
       "std    2.159923e-01       0.216059  ...  2.157661e-01  2.157362e-01   \n",
       "min    7.850462e-17       0.000000  ...  5.928594e-17  4.163336e-17   \n",
       "25%    5.337120e-01       0.534212  ...  5.322081e-01  5.324213e-01   \n",
       "50%    7.236799e-01       0.723734  ...  7.213209e-01  7.217035e-01   \n",
       "75%    8.369641e-01       0.837273  ...  8.360165e-01  8.363003e-01   \n",
       "max    9.946186e-01       0.994560  ...  9.943800e-01  9.944133e-01   \n",
       "\n",
       "               3.86          3.88            3.9          3.92          3.94  \\\n",
       "count  6.400000e+05  6.400000e+05  640000.000000  6.400000e+05  6.400000e+05   \n",
       "mean   6.656958e-01  6.655348e-01       0.665172  6.649860e-01  6.649359e-01   \n",
       "std    2.157286e-01  2.158523e-01       0.216179  2.159365e-01  2.163339e-01   \n",
       "min    6.206335e-17  2.775558e-17       0.000000  5.551115e-17  5.551115e-17   \n",
       "25%    5.320344e-01  5.318954e-01       0.531747  5.305231e-01  5.308626e-01   \n",
       "50%    7.217745e-01  7.216917e-01       0.721434  7.207618e-01  7.209027e-01   \n",
       "75%    8.363553e-01  8.363261e-01       0.835910  8.359788e-01  8.358903e-01   \n",
       "max    9.946468e-01  9.943963e-01       0.994473  9.942726e-01  9.948500e-01   \n",
       "\n",
       "                3.96          3.98             4  \n",
       "count  640000.000000  6.400000e+05  6.400000e+05  \n",
       "mean        0.665539  6.655460e-01  6.656456e-01  \n",
       "std         0.215825  2.160998e-01  2.158734e-01  \n",
       "min         0.000000  5.551115e-17  1.110223e-16  \n",
       "25%         0.531658  5.316424e-01  5.315743e-01  \n",
       "50%         0.721286  7.217253e-01  7.214615e-01  \n",
       "75%         0.836058  8.364130e-01  8.364736e-01  \n",
       "max         0.994953  9.947453e-01  9.940722e-01  \n",
       "\n",
       "[8 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = r\"C:\\Users\\mktha\\Documents\\projects\\felix\\data\\extended500000.mat\"\n",
    "import scipy.io\n",
    "f = scipy.io.loadmat(ds_path)\n",
    "df = pd.DataFrame(f['extended500000mag'])\n",
    "# drop the first column\n",
    "df = df.drop([0], axis=1)\n",
    "# rename the columns\n",
    "df.columns = headers\n",
    "# concat the two dataframes vertically\n",
    "df_mag = pd.concat([df_mag, df], axis=0)\n",
    "print(df_mag.shape)\n",
    "df_mag.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "phase"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "csv_path = r\"C:\\Users\\mktha\\Documents\\projects\\felix\\data\\RawDataPhaseExtended(newdataset).csv\"\n",
    "\n",
    "df_phase = pd.read_csv(csv_path, header=0, index_col=0)\n",
    "\n",
    "# get the headers\n",
    "headers = df_phase.columns.values.tolist()\n",
    "print(df_phase.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(df_mag), size=3)\n",
    "for i in indices:\n",
    "    mag = df_mag.iloc[i][8:]\n",
    "    phase = df_phase.iloc[i][8:]\n",
    "    # convert phase to radians\n",
    "    phase = np.deg2rad(phase)\n",
    "    real = mag * np.cos(phase)\n",
    "    imag = mag * np.sin(phase)\n",
    "    # plot phase, mag, real, imag separately side by side\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    axs[0].plot(phase)\n",
    "    axs[0].set_title('Phase')\n",
    "    axs[1].plot(mag)\n",
    "    axs[1].set_title('Magnitude')\n",
    "    axs[2].plot(real)\n",
    "    axs[2].set_title('Real')\n",
    "    axs[3].plot(imag)\n",
    "    axs[3].set_title('Imaginary')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = df_mag\n",
    "param1 = df1['eps1 ']\n",
    "param2 = df1['eps2 ']\n",
    "param3 = df1['eps3 ']\n",
    "param4 = df1['eps4 ']\n",
    "param5 = df1['t1 [mm]']\n",
    "param6 = df1['t2 [mm]']\n",
    "param7 = df1['t3 [mm]']\n",
    "param8 = df1['t4 [mm]']\n",
    "# get the columns from 9 to the end\n",
    "values = df1.iloc[:, 8:]\n",
    "\n",
    "# convert to numpy array\n",
    "param1 = param1.values\n",
    "param2 = param2.values\n",
    "param3 = param3.values\n",
    "param4 = param4.values\n",
    "param5 = param5.values\n",
    "param6 = param6.values\n",
    "param7 = param7.values\n",
    "param8 = param8.values\n",
    "values = values.to_numpy()\n",
    "# values = values[:, 50:51]\n",
    "\n",
    "# standardize\n",
    "param1_scaler = preprocessing.StandardScaler()\n",
    "param1 = param1_scaler.fit_transform(param1.reshape(-1, 1))\n",
    "param2_scaler = preprocessing.StandardScaler()\n",
    "param2 = param2_scaler.fit_transform(param2.reshape(-1, 1))\n",
    "param3_scaler = preprocessing.StandardScaler()\n",
    "param3 = param3_scaler.fit_transform(param3.reshape(-1, 1))\n",
    "param4_scaler = preprocessing.StandardScaler()\n",
    "param4 = param4_scaler.fit_transform(param4.reshape(-1, 1))\n",
    "param5_scaler = preprocessing.StandardScaler()\n",
    "param5 = param5_scaler.fit_transform(param5.reshape(-1, 1))\n",
    "param6_scaler = preprocessing.StandardScaler()\n",
    "param6 = param6_scaler.fit_transform(param6.reshape(-1, 1))\n",
    "param7_scaler = preprocessing.StandardScaler()\n",
    "param7 = param7_scaler.fit_transform(param7.reshape(-1, 1))\n",
    "param8_scaler = preprocessing.StandardScaler()\n",
    "param8 = param8_scaler.fit_transform(param8.reshape(-1, 1))\n",
    "values_scaler = preprocessing.StandardScaler()\n",
    "values = values_scaler.fit_transform(values)\n",
    "\n",
    "inputs = np.column_stack((param1, param2, param3, param4, param5, param6, param7, param8))\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, values, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config\n",
    "config = {\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 300,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'num_layers': 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: mksthabet. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\mktha\\AppData\\Local\\Temp\\ipykernel_14776\\2234956762.py 6 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 1043, in init\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 689, in init\n",
      "    wandb will automatically resume the run with that id. Otherwise,\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\backend\\backend.py\", line 246, in cleanup\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 475, in join\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 666, in join\n",
      "    self._publish(rec)\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 472, in _communicate_shutdown\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 226, in _communicate\n",
      "  File \"c:\\Users\\mktha\\anaconda3\\envs\\medical_env\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 231, in _communicate_async\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# setup wandb\n",
    "wandb.login()\n",
    "# root_path = Path(r'C:\\Users\\mktha\\Documents\\projects\\felix')\n",
    "\n",
    "# model_dir = root_path / 'models'\n",
    "wandb.init(project='Felix',\n",
    "            name='',\n",
    "            notes='',\n",
    "            tags=[''],\n",
    "            entity='mksthabet',\n",
    "            config=config)\n",
    "# # get run name\n",
    "# run_name = wandb.run.name\n",
    "# # get run dir\n",
    "# run_dir = wandb.run.dir\n",
    "\n",
    "# wandb.run.log_code('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 2048)         18432       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_40 (LayerNo (None, 2048)         4096        dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 2048)         0           layer_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 2048)         4196352     dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_41 (LayerNo (None, 2048)         4096        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 2048)         0           layer_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 2048)         0           dropout_41[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 2048)         4196352     add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_42 (LayerNo (None, 2048)         4096        dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 2048)         0           layer_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 2048)         0           dropout_42[0][0]                 \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 2048)         4196352     add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_43 (LayerNo (None, 2048)         4096        dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 2048)         0           layer_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 2048)         0           dropout_43[0][0]                 \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 2048)         4196352     add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_44 (LayerNo (None, 2048)         4096        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 2048)         0           layer_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 2048)         0           dropout_44[0][0]                 \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 2048)         4196352     add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_45 (LayerNo (None, 2048)         4096        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 2048)         0           layer_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 2048)         0           dropout_45[0][0]                 \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 2048)         4196352     add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_46 (LayerNo (None, 2048)         4096        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 2048)         0           layer_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 2048)         0           dropout_46[0][0]                 \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 2048)         4196352     add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_47 (LayerNo (None, 2048)         4096        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 2048)         0           layer_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 2048)         0           dropout_47[0][0]                 \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 2048)         4196352     add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_48 (LayerNo (None, 2048)         4096        dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 2048)         0           layer_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 2048)         0           dropout_48[0][0]                 \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 2048)         4196352     add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_49 (LayerNo (None, 2048)         4096        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 2048)         0           layer_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2048)         0           dropout_49[0][0]                 \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 2048)         4196352     add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_50 (LayerNo (None, 2048)         4096        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 2048)         0           layer_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 2048)         0           dropout_50[0][0]                 \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 2048)         4196352     add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_51 (LayerNo (None, 2048)         4096        dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 2048)         0           layer_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 2048)         0           dropout_51[0][0]                 \n",
      "                                                                 add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 2048)         4196352     add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_52 (LayerNo (None, 2048)         4096        dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 2048)         0           layer_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 2048)         0           dropout_52[0][0]                 \n",
      "                                                                 add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 2048)         4196352     add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_53 (LayerNo (None, 2048)         4096        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 2048)         0           layer_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 2048)         0           dropout_53[0][0]                 \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 2048)         4196352     add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_54 (LayerNo (None, 2048)         4096        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 2048)         0           layer_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 2048)         0           dropout_54[0][0]                 \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 101)          206949      add_51[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 59,035,749\n",
      "Trainable params: 59,035,749\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/300\n",
      "19000/19000 [==============================] - 228s 12ms/step - loss: 1.0415 - mae: 0.8119 - val_loss: 0.5604 - val_mae: 0.6658\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56037, saving model to ../models\\best_model.h5\n",
      "Epoch 2/300\n",
      "19000/19000 [==============================] - 225s 12ms/step - loss: 0.8834 - mae: 0.7590 - val_loss: 0.6174 - val_mae: 0.7106\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.56037\n",
      "Epoch 3/300\n",
      "19000/19000 [==============================] - 225s 12ms/step - loss: 0.8613 - mae: 0.7487 - val_loss: 0.5707 - val_mae: 0.6746\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56037\n",
      "Epoch 4/300\n",
      "19000/19000 [==============================] - 222s 12ms/step - loss: 0.8460 - mae: 0.7408 - val_loss: 0.5533 - val_mae: 0.6613\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56037 to 0.55333, saving model to ../models\\best_model.h5\n",
      "Epoch 5/300\n",
      "19000/19000 [==============================] - 225s 12ms/step - loss: 0.8328 - mae: 0.7338 - val_loss: 0.5721 - val_mae: 0.6714\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55333\n",
      "Epoch 6/300\n",
      "19000/19000 [==============================] - 227s 12ms/step - loss: 0.8227 - mae: 0.7284 - val_loss: 0.5744 - val_mae: 0.6740\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55333\n",
      "Epoch 7/300\n",
      "19000/19000 [==============================] - 225s 12ms/step - loss: 0.8148 - mae: 0.7242 - val_loss: 0.6148 - val_mae: 0.6988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55333\n",
      "Epoch 8/300\n",
      "19000/19000 [==============================] - 225s 12ms/step - loss: 0.8071 - mae: 0.7201 - val_loss: 0.6130 - val_mae: 0.6956\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.55333\n",
      "Epoch 9/300\n",
      "19000/19000 [==============================] - 223s 12ms/step - loss: 0.7988 - mae: 0.7157 - val_loss: 0.6090 - val_mae: 0.6890\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.55333\n",
      "Epoch 10/300\n",
      "19000/19000 [==============================] - 217s 11ms/step - loss: 0.7910 - mae: 0.7115 - val_loss: 0.6178 - val_mae: 0.6925\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.55333\n",
      "Epoch 11/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.7834 - mae: 0.7073 - val_loss: 0.6089 - val_mae: 0.6866\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.55333\n",
      "Epoch 12/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.7751 - mae: 0.7028 - val_loss: 0.6289 - val_mae: 0.6991\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.55333\n",
      "Epoch 13/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.7652 - mae: 0.6972 - val_loss: 0.6448 - val_mae: 0.7030\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.55333\n",
      "Epoch 14/300\n",
      "19000/19000 [==============================] - 214s 11ms/step - loss: 0.7518 - mae: 0.6897 - val_loss: 0.6501 - val_mae: 0.7046\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.55333\n",
      "Epoch 15/300\n",
      "19000/19000 [==============================] - 209s 11ms/step - loss: 0.7348 - mae: 0.6801 - val_loss: 0.6734 - val_mae: 0.7143\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.55333\n",
      "Epoch 16/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.7146 - mae: 0.6686 - val_loss: 0.6641 - val_mae: 0.7051\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.55333\n",
      "Epoch 17/300\n",
      "19000/19000 [==============================] - 213s 11ms/step - loss: 0.6913 - mae: 0.6552 - val_loss: 0.6730 - val_mae: 0.7060\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.55333\n",
      "Epoch 18/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.6634 - mae: 0.6389 - val_loss: 0.6921 - val_mae: 0.7127\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.55333\n",
      "Epoch 19/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.6300 - mae: 0.6194 - val_loss: 0.7025 - val_mae: 0.7109\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.55333\n",
      "Epoch 20/300\n",
      "19000/19000 [==============================] - 210s 11ms/step - loss: 0.5958 - mae: 0.5990 - val_loss: 0.7258 - val_mae: 0.7205\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55333\n",
      "Epoch 21/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.5668 - mae: 0.5817 - val_loss: 0.7494 - val_mae: 0.7306\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.55333\n",
      "Epoch 22/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.5413 - mae: 0.5662 - val_loss: 0.7567 - val_mae: 0.7291\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55333\n",
      "Epoch 23/300\n",
      "19000/19000 [==============================] - 213s 11ms/step - loss: 0.5191 - mae: 0.5526 - val_loss: 0.7720 - val_mae: 0.7333\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.55333\n",
      "Epoch 24/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.4994 - mae: 0.5403 - val_loss: 0.7769 - val_mae: 0.7336\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.55333\n",
      "Epoch 25/300\n",
      "19000/19000 [==============================] - 215s 11ms/step - loss: 0.4815 - mae: 0.5291 - val_loss: 0.7935 - val_mae: 0.7404\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.55333\n",
      "Epoch 26/300\n",
      "19000/19000 [==============================] - 214s 11ms/step - loss: 0.4657 - mae: 0.5191 - val_loss: 0.8062 - val_mae: 0.7445\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.55333\n",
      "Epoch 27/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.4520 - mae: 0.5104 - val_loss: 0.7987 - val_mae: 0.7367\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.55333\n",
      "Epoch 28/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.4405 - mae: 0.5029 - val_loss: 0.8136 - val_mae: 0.7454\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.55333\n",
      "Epoch 29/300\n",
      "19000/19000 [==============================] - 209s 11ms/step - loss: 0.4300 - mae: 0.4961 - val_loss: 0.8291 - val_mae: 0.7499\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.55333\n",
      "Epoch 30/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.4207 - mae: 0.4899 - val_loss: 0.8426 - val_mae: 0.7546\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.55333\n",
      "Epoch 31/300\n",
      "19000/19000 [==============================] - 211s 11ms/step - loss: 0.4122 - mae: 0.4843 - val_loss: 0.8331 - val_mae: 0.7493\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.55333\n",
      "Epoch 32/300\n",
      "19000/19000 [==============================] - 213s 11ms/step - loss: 0.4044 - mae: 0.4791 - val_loss: 0.8245 - val_mae: 0.7444\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.55333\n",
      "Epoch 33/300\n",
      "19000/19000 [==============================] - 210s 11ms/step - loss: 0.3973 - mae: 0.4743 - val_loss: 0.8443 - val_mae: 0.7535\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.55333\n",
      "Epoch 34/300\n",
      "19000/19000 [==============================] - 212s 11ms/step - loss: 0.3909 - mae: 0.4700 - val_loss: 0.8435 - val_mae: 0.7513\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.55333\n",
      "Epoch 00034: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = y_train.shape[1]\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(num_inputs,))\n",
    "x = layers.Dense(config['hidden_dim'], activation='relu')(input_layer)\n",
    "x = layers.LayerNormalization()(x)\n",
    "x = layers.Dropout(config['dropout'])(x)\n",
    "for layer in range(config['num_layers'] - 1):\n",
    "    residual = x\n",
    "    x = layers.Dense(config['hidden_dim'], activation='relu')(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dropout(config['dropout'])(x)\n",
    "    # x = layers.Dense(hidden_dim, activation='relu')(x)\n",
    "    # x = layers.LayerNormalization()(x)\n",
    "    # x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Add()([x, residual])\n",
    "output_layer = layers.Dense(num_outputs)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='../models/best_model.h5', monitor='val_loss',\n",
    "                                                 save_best_only=True, verbose=1)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1)\n",
    "# wandb_callback = wandb.keras.WandbCallback(monitor=\"val_loss\",\n",
    "#                                                    log_weights=True, save_model=False)\n",
    "model.fit(X_train, y_train, epochs=config['epochs'], batch_size=config['batch_size'], validation_data=(X_test, y_test),\n",
    "          callbacks=[lr_callback, cp_callback, es_callback])\n",
    "\n",
    "# plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.0164667545410087\n",
      "MAE:  0.09535560572292531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict\n",
    "model = tf.keras.models.load_model('../models/best_model.h5')\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = values_scaler.inverse_transform(y_pred)\n",
    "y_test = values_scaler.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "# calculate abs error along axis 1\n",
    "error_abs = np.abs(y_pred - y_test)\n",
    "square_error = np.square(y_pred - y_test)\n",
    "mse = np.mean(np.square(error_abs))\n",
    "mae = np.mean(error_abs)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"MAE: \", mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "575e40928c11cd0238fd6bc914f6b16dd1c4601e7697ba6b3aa0da44f5f3f5bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
